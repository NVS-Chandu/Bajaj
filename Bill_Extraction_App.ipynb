{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from typing import List, Literal, Optional\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel, Field\n",
        "from pdf2image import convert_from_bytes\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize FastAPI\n",
        "app = FastAPI(title=\"Bill Extraction API\", description=\"AI-powered invoice line item extractor\")\n",
        "\n",
        "# Initialize OpenAI Client\n",
        "# The API key must be set in the environment variables (e.g., via Railway/Render dashboard)\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# --- Pydantic Models (Strictly matching the provided JSON Schema) ---\n",
        "\n",
        "class BillItem(BaseModel):\n",
        "    item_name: str = Field(description=\"Name of the item exactly as mentioned in the bill\")\n",
        "    item_amount: float = Field(description=\"Net Amount of the item post discounts\")\n",
        "    item_rate: float = Field(description=\"Unit rate of the item\")\n",
        "    item_quantity: float = Field(description=\"Quantity of the item\")\n",
        "\n",
        "class PageData(BaseModel):\n",
        "    page_no: str = Field(description=\"The page number of the document\")\n",
        "    page_type: Literal[\"Bill Detail\", \"Final Bill\", \"Pharmacy\"] = Field(\n",
        "        description=\"Classify the page. 'Bill Detail' for itemized lists, 'Pharmacy' for medical lists, 'Final Bill' for summary pages.\"\n",
        "    )\n",
        "    bill_items: List[BillItem]\n",
        "\n",
        "class ExtractionResult(BaseModel):\n",
        "    \"\"\"Container for the structured output from the LLM\"\"\"\n",
        "    pages: List[PageData]\n",
        "\n",
        "# --- API Request/Response Schemas ---\n",
        "\n",
        "class ExtractionRequest(BaseModel):\n",
        "    document: str  # The URL of the file\n",
        "\n",
        "class TokenUsage(BaseModel):\n",
        "    total_tokens: int\n",
        "    input_tokens: int\n",
        "    output_tokens: int\n",
        "\n",
        "class ResponseData(BaseModel):\n",
        "    pagewise_line_items: List[PageData]\n",
        "    total_item_count: int\n",
        "\n",
        "class APIResponse(BaseModel):\n",
        "    is_success: bool\n",
        "    token_usage: TokenUsage\n",
        "    data: Optional[ResponseData] = None\n",
        "    error: Optional[str] = None\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def download_file(url: str) -> tuple[bytes, str]:\n",
        "    \"\"\"Downloads file from URL and returns bytes and content-type.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        return response.content, response.headers.get(\"Content-Type\", \"\")\n",
        "    except requests.RequestException as e:\n",
        "        raise HTTPException(status_code=400, detail=f\"Failed to download document: {str(e)}\")\n",
        "\n",
        "def process_document_to_images(file_content: bytes, content_type: str) -> List[str]:\n",
        "    \"\"\"Converts PDF or Image bytes to a list of base64 encoded strings.\"\"\"\n",
        "    base64_images = []\n",
        "\n",
        "    # Handle PDF\n",
        "    if \"pdf\" in content_type.lower() or file_content.startswith(b\"%PDF\"):\n",
        "        try:\n",
        "            # Convert PDF to images (requires poppler-utils installed on system)\n",
        "            images = convert_from_bytes(file_content)\n",
        "            for img in images:\n",
        "                buffered = BytesIO()\n",
        "                img.save(buffered, format=\"JPEG\", quality=85)\n",
        "                img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "                base64_images.append(img_str)\n",
        "        except Exception as e:\n",
        "            raise HTTPException(status_code=500, detail=f\"PDF processing failed: {str(e)}\")\n",
        "    # Handle Images (PNG/JPG/JPEG)\n",
        "    else:\n",
        "        try:\n",
        "            # We assume it's an image. You could add PIL validation here if strictly needed.\n",
        "            img_str = base64.b64encode(file_content).decode(\"utf-8\")\n",
        "            base64_images.append(img_str)\n",
        "        except Exception as e:\n",
        "             raise HTTPException(status_code=400, detail=f\"Image processing failed: {str(e)}\")\n",
        "\n",
        "    return base64_images\n",
        "\n",
        "# --- Core Endpoint ---\n",
        "\n",
        "@app.post(\"/extract-bill-data\", response_model=APIResponse)\n",
        "async def extract_bill_data(request: ExtractionRequest):\n",
        "    if not api_key:\n",
        "        raise HTTPException(status_code=500, detail=\"Server Configuration Error: OPENAI_API_KEY is missing.\")\n",
        "\n",
        "    try:\n",
        "        # 1. Download File\n",
        "        file_content, content_type = download_file(request.document)\n",
        "\n",
        "        # 2. Convert to Images (Base64)\n",
        "        base64_images = process_document_to_images(file_content, content_type)\n",
        "\n",
        "        # 3. Prepare Prompt for GPT-4o\n",
        "        system_prompt = \"\"\"\n",
        "        You are an expert invoice data extraction AI. Your goal is to digitize bills accurately.\n",
        "\n",
        "        CRITICAL EXTRACTION RULES:\n",
        "        1. **Goal**: Extract specific line items (products, services, medicines).\n",
        "        2. **Values**:\n",
        "           - 'item_amount': This MUST be the total cost for that line (Rate * Quantity).\n",
        "           - 'item_rate': Unit price. If missing, calculate as Amount / Quantity.\n",
        "           - 'item_quantity': If missing, assume 1.\n",
        "        3. **Double Counting Prevention (The \"Final Total\" Rule)**:\n",
        "           - Do NOT extract \"Subtotal\", \"Total\", \"Balance Due\", or \"Grand Total\" as line items. These are aggregations.\n",
        "           - If a page is a 'Final Bill' or 'Summary' that re-lists items from previous pages, return an EMPTY list for that page to avoid double counting.\n",
        "           - ONLY extract items from a 'Final Bill' page if they are NEW charges (e.g., 'Delivery Fee', 'Service Tax', 'Discount') that were not listed on the detail pages.\n",
        "        4. **Validation**: Ensure the sum of all 'item_amount' values roughly equals the invoice grand total.\n",
        "        \"\"\"\n",
        "\n",
        "        user_content = [\n",
        "            {\"type\": \"text\", \"text\": \"Analyze these invoice pages. Extract the line items into the structured JSON format.\"}\n",
        "        ]\n",
        "\n",
        "        # Add all pages to the payload\n",
        "        for img in base64_images:\n",
        "            user_content.append({\n",
        "                \"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img}\", \"detail\": \"high\"}\n",
        "            })\n",
        "\n",
        "        # 4. Call OpenAI with Structured Outputs\n",
        "        completion = client.beta.chat.completions.parse(\n",
        "            model=\"gpt-4o-2024-08-06\", # Using the latest model for best Vision performance\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_content},\n",
        "            ],\n",
        "            response_format=ExtractionResult,\n",
        "            temperature=0.0, # Zero temperature for maximum determinism\n",
        "        )\n",
        "\n",
        "        result_data = completion.choices[0].message.parsed\n",
        "        usage = completion.usage\n",
        "\n",
        "        # 5. Post-Processing: Calculate Total Item Count\n",
        "        total_count = sum(len(page.bill_items) for page in result_data.pages)\n",
        "\n",
        "        # 6. Return Formatted Response\n",
        "        return APIResponse(\n",
        "            is_success=True,\n",
        "            token_usage=TokenUsage(\n",
        "                total_tokens=usage.total_tokens,\n",
        "                input_tokens=usage.prompt_tokens,\n",
        "                output_tokens=usage.completion_tokens\n",
        "            ),\n",
        "            data=ResponseData(\n",
        "                pagewise_line_items=result_data.pages,\n",
        "                total_item_count=total_count\n",
        "            )\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        # Return a failed response structure rather than a 500 error if possible\n",
        "        return APIResponse(\n",
        "            is_success=False,\n",
        "            token_usage=TokenUsage(total_tokens=0, input_tokens=0, output_tokens=0),\n",
        "            data=ResponseData(pagewise_line_items=[], total_item_count=0), # Empty data on failure\n",
        "            error=str(e)\n",
        "        )\n",
        "\n",
        "# For local testing: uvicorn main:app --reload"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "PyOITDUbG1oC"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}